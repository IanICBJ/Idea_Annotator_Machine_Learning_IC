{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a22ac79c",
   "metadata": {},
   "source": [
    "## FYP Sprint 3 ML training\n",
    "\n",
    "### Ian Chia \n",
    "### 230746D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df849a57",
   "metadata": {},
   "source": [
    "### Mini GamePlan Idea to give the teacher some sort of understanding of what i am trying to do \n",
    "\n",
    "1) Build a mini version of the ML pipeline\n",
    "\n",
    "\n",
    "2) Define the shape of the JSON\n",
    "\n",
    "\n",
    "3) Use a tiny dataset (few examples made up on the spot) Why? : So we can test the full flow without risking the real MongoDB data\n",
    "\n",
    "\n",
    "4) Connect to your real data (350 annotated examples) : Once the testing is complete we will replace everything with the real one.\n",
    "\n",
    "### Why are we doing this:\n",
    "\n",
    "So right now, we just use the mini version because:\n",
    "\n",
    "It’s faster — we don’t need to connect to MongoDB yet.\n",
    "\n",
    "It’s safer — we can test code without touching your real data.\n",
    "\n",
    "It’s simple — we only need 5 core slots to prove the system works.\n",
    "\n",
    "Once it works, we’ll swap in the real schema (which already lives in your app)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc6b630",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc5363d",
   "metadata": {},
   "source": [
    "### Mini Testing pipeline :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a52530c",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520d62fd",
   "metadata": {},
   "source": [
    "### Cell 0 — Install & Import needed libaries\n",
    "\n",
    "Installs the Hugging Face tools we need to train a small T5 model.\n",
    "Run once per fresh environment. No output is expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc70f44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets seqeval jsonschema accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e7d81ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18dc8f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ian Chia\\.conda\\envs\\it3386\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ian Chia\\.conda\\envs\\it3386\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any\n",
    "import json, re, random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, DataCollatorForTokenClassification, TrainingArguments, Trainer\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score\n",
    "from jsonschema import validate, ValidationError\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, TrainingArguments, Trainer\n",
    "from datasets import Dataset, DatasetDict\n",
    "import json, numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b1e86e",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fdd2ad",
   "metadata": {},
   "source": [
    "### Cell 1 — tiny seed dataset\n",
    "\n",
    "Sets the 5 slots (ACTOR, ACTION, OBJECT, LOCATION, TIME).\n",
    "\n",
    "Creates a mini practice dataset (3 train / 1 dev / 1 test).\n",
    "\n",
    "Wraps each sentence into a prompt like:\n",
    "“Extract case-frame JSON… Text: \"…\" JSON:”\n",
    "\n",
    "Stores the correct JSON as the target.\n",
    "This gives T5 examples of what to write."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5eb3132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'target'],\n",
       "        num_rows: 3\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input', 'target'],\n",
       "        num_rows: 1\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input', 'target'],\n",
       "        num_rows: 1\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SLOTS = [\"ACTOR\",\"ACTION\",\"OBJECT\",\"LOCATION\",\"TIME\"]\n",
    "\n",
    "# tiny seed data (same content as BERT demo)\n",
    "examples = [\n",
    "    (\"Alice kicked the ball at the park yesterday.\",\n",
    "     {\"ACTOR\":\"Alice\",\"ACTION\":\"kicked\",\"OBJECT\":\"the ball\",\"LOCATION\":\"the park\",\"TIME\":\"yesterday\"}),\n",
    "    (\"Bob repaired the bike in the garage last night.\",\n",
    "     {\"ACTOR\":\"Bob\",\"ACTION\":\"repaired\",\"OBJECT\":\"the bike\",\"LOCATION\":\"the garage\",\"TIME\":\"last night\"}),\n",
    "    (\"Chloe reads a novel at home every morning.\",\n",
    "     {\"ACTOR\":\"Chloe\",\"ACTION\":\"reads\",\"OBJECT\":\"a novel\",\"LOCATION\":\"home\",\"TIME\":\"every morning\"}),\n",
    "    (\"Daniel cooked pasta in the kitchen at noon.\",\n",
    "     {\"ACTOR\":\"Daniel\",\"ACTION\":\"cooked\",\"OBJECT\":\"pasta\",\"LOCATION\":\"the kitchen\",\"TIME\":\"at noon\"}),\n",
    "    (\"Eva painted the fence outside on Sunday.\",\n",
    "     {\"ACTOR\":\"Eva\",\"ACTION\":\"painted\",\"OBJECT\":\"the fence\",\"LOCATION\":\"outside\",\"TIME\":\"on Sunday\"}),\n",
    "]\n",
    "\n",
    "# split 3/1/1\n",
    "train = examples[:3]; dev = examples[3:4]; test = examples[4:5]\n",
    "\n",
    "def to_pairs(pairs):\n",
    "    recs = []\n",
    "    for text, y in pairs:\n",
    "        prompt = (\n",
    "          \"Extract a case-frame JSON with keys ACTOR, ACTION, OBJECT, LOCATION, TIME.\\n\"\n",
    "          f'Text: \"{text}\"\\nJSON:'\n",
    "        )\n",
    "        recs.append({\"input\": prompt, \"target\": json.dumps(y)})\n",
    "    return recs\n",
    "\n",
    "ds = DatasetDict({\n",
    "    \"train\": Dataset.from_list(to_pairs(train)),\n",
    "    \"validation\": Dataset.from_list(to_pairs(dev)),\n",
    "    \"test\": Dataset.from_list(to_pairs(test)),\n",
    "})\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d0d94f",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00e731",
   "metadata": {},
   "source": [
    "### Cell 2 — Tokenize\n",
    "\n",
    "Loads a small T5 model (e.g., flan-t5-small).\n",
    "\n",
    "Converts each prompt/target into token IDs the model understands.\n",
    "\n",
    "Pairs inputs with the correct output IDs (labels) so the model can learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0b51cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ian Chia\\.conda\\envs\\it3386\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ian Chia\\.cache\\huggingface\\hub\\models--google--flan-t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Map:   0%|                                                                                | 0/3 [00:00<?, ? examples/s]C:\\Users\\ian Chia\\.conda\\envs\\it3386\\lib\\site-packages\\transformers\\tokenization_utils_base.py:4006: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map: 100%|████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 41.63 examples/s]\n",
      "Map: 100%|████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 88.20 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 142.05 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL = \"google/flan-t5-small\"  # or \"t5-small\"\n",
    "tok = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL)\n",
    "\n",
    "def tok_fn(batch):\n",
    "    model_in = tok(batch[\"input\"], truncation=True)\n",
    "    with tok.as_target_tokenizer():\n",
    "        labels = tok(batch[\"target\"], truncation=True)\n",
    "    model_in[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_in\n",
    "\n",
    "tok_ds = ds.map(tok_fn, batched=True, remove_columns=ds[\"train\"].column_names)\n",
    "collator = DataCollatorForSeq2Seq(tok, model=model)\n",
    "tok_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2169d220",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980df072",
   "metadata": {},
   "source": [
    "### Cell 3 — Train (short)\n",
    "\n",
    "Sets training settings (epochs, batch size, learning rate).\n",
    "\n",
    "Trains on the 3 tiny train examples and evaluates on the 1 dev example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c673a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ian Chia\\AppData\\Local\\Temp\\ipykernel_24304\\1404849123.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "C:\\Users\\ian Chia\\.conda\\envs\\it3386\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:04, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ian Chia\\.conda\\envs\\it3386\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.364403009414673,\n",
       " 'eval_runtime': 0.354,\n",
       " 'eval_samples_per_second': 2.825,\n",
       " 'eval_steps_per_second': 2.825,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"./models/t5_text2json\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    save_total_limit=1,\n",
    "    report_to=[]   # keeps it quiet\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tok_ds[\"train\"],\n",
    "    eval_dataset=tok_ds[\"validation\"],\n",
    "    data_collator=collator,\n",
    "    tokenizer=tok,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e7c094",
   "metadata": {},
   "source": [
    "### Explanation: \n",
    "\n",
    "**eval_loss** = “how wrong” the model still is on the dev prompt (lower is better).\n",
    "\n",
    "You only see loss (not F1) because we didn’t ask the trainer to generate here; that’s okay — we generate in Cell 4.\n",
    "\n",
    "With 3 train examples, loss won’t look great. This cell mainly proves training runs end-to-end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bf87ce",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9906f1",
   "metadata": {},
   "source": [
    "### Cell 4 — Generate on test + parse + simple Slot-F1\n",
    "\n",
    "Asks T5 to write the JSON for the test sentence (it “decodes” its understanding).\n",
    "\n",
    "Tries to parse what it wrote into a Python dict.\n",
    "\n",
    "Compares predicted JSON vs gold JSON slot by slot (exact match) to compute a simple Slot-F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ef30467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT: Eva painted the fence outside on Sunday.\n",
      "PRED: {'ACTOR': None, 'ACTION': None, 'OBJECT': None, 'LOCATION': None, 'TIME': None}\n",
      "GOLD: {'ACTOR': 'Eva', 'ACTION': 'painted', 'OBJECT': 'the fence', 'LOCATION': 'outside', 'TIME': 'on Sunday'}\n",
      "Slot-F1: {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# small helper to ask T5 to produce JSON for a sentence\n",
    "def generate_json(text):\n",
    "    prompt = (\n",
    "      \"Extract a case-frame JSON with keys ACTOR, ACTION, OBJECT, LOCATION, TIME.\\n\"\n",
    "      f'Text: \"{text}\"\\nJSON:'\n",
    "    )\n",
    "    ids = tok(prompt, return_tensors=\"pt\")\n",
    "    # put tensors on same device as model (handles CPU/GPU safely)\n",
    "    ids = {k: v.to(model.device) for k, v in ids.items()}\n",
    "    gen_ids = model.generate(**ids, max_new_tokens=80)\n",
    "    s = tok.decode(gen_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # trim to JSON block if model adds extra text\n",
    "    if \"{\" in s and \"}\" in s:\n",
    "        s = s[s.find(\"{\"): s.rfind(\"}\")+1]\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except:\n",
    "        # fallback if parsing fails\n",
    "        return {k: None for k in SLOTS}\n",
    "\n",
    "# pull raw text & gold label from the test set\n",
    "test_input = ds[\"test\"][0][\"input\"]\n",
    "text = test_input.split('Text: \"')[1].split('\"\\nJSON:')[0]\n",
    "gold = json.loads(ds[\"test\"][0][\"target\"])\n",
    "\n",
    "pred = generate_json(text)\n",
    "print(\"TEXT:\", text)\n",
    "print(\"PRED:\", pred)\n",
    "print(\"GOLD:\", gold)\n",
    "\n",
    "# very simple exact-match Slot-F1 (per-slot equality)\n",
    "def slot_f1(pred, gold):\n",
    "    tp=fp=fn=0\n",
    "    for k in SLOTS:\n",
    "        p=(pred.get(k) or \"\").strip().lower()\n",
    "        g=(gold.get(k) or \"\").strip().lower()\n",
    "        if p and g and p==g: tp+=1\n",
    "        elif p and g and p!=g: fp+=1; fn+=1\n",
    "        elif p and not g: fp+=1\n",
    "        elif not p and g: fn+=1\n",
    "    prec = tp/(tp+fp) if tp+fp else 0.0\n",
    "    rec  = tp/(tp+fn) if tp+fn else 0.0\n",
    "    f1   = 2*prec*rec/(prec+rec) if prec+rec else 0.0\n",
    "    return {\"precision\":prec, \"recall\":rec, \"f1\":f1}\n",
    "\n",
    "print(\"Slot-F1:\", slot_f1(pred, gold))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad52a7b3",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "\n",
    "The model didn’t learn enough from only 3 training examples, so it produced an “empty” JSON (all None).\n",
    "\n",
    "Exact-match Slot-F1 is 0.0 because none of the five slots match the gold answer.\n",
    "\n",
    "This is normal for a micro toy run; we need more data and/or more training to get useful outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c8e06d",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7136427",
   "metadata": {},
   "source": [
    "### Cell 5 — Save artifacts (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfae135a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saved'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "Path(\"results\").mkdir(exist_ok=True)\n",
    "with open(\"results/t5_test_result.json\",\"w\") as f:\n",
    "    json.dump({\"text\":text,\"pred\":pred,\"gold\":gold}, f, indent=2)\n",
    "\"saved\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe072cc",
   "metadata": {},
   "source": [
    "Saves one test example (text, predicted JSON, gold JSON) to results/t5_test_result.json so it can be screenshotted or attach it for the proposal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e1f423",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026cd6c7",
   "metadata": {},
   "source": [
    "### Conclusion :\n",
    "\n",
    "- We completed a T5 text→JSON prototype on a tiny seed set.\n",
    "\n",
    "- Training/eval ran successfully, but outputs are poor on such little data — expected.\n",
    "\n",
    "- This prototype proves the pipeline: prompt → T5 generate → parse JSON → Slot-F1.\n",
    "\n",
    "**Next steps:**\n",
    "\n",
    "1) Export the 350 MongoDB annotations into {\"text\",\"target_json\"} and re-train (5–10 epochs).\n",
    "\n",
    "2) Compare with your BERT track using the same split and report Slot-F1 per slot and Frame-Validity %.\n",
    "\n",
    "3) Carry the better performing track (BERT or T5) into your Step-7 proposal with metrics + example predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86292b81",
   "metadata": {},
   "source": [
    "----------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mlops)",
   "language": "python",
   "name": "mlops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
