{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65f771a1",
   "metadata": {},
   "source": [
    "## FYP Sprint 4 \n",
    "### Ian Chia \n",
    "### 230746D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7e3b3d",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9776ee",
   "metadata": {},
   "source": [
    "### Improving T5 JSON Output (Table of Contents)\n",
    "\n",
    "### 1) Track 2.1 — Setup & Loading\n",
    "\n",
    "### 2) Track 2.2 — Safer Decoding\n",
    "\n",
    "### 3) Track 2.3 — JSON Repair Pipeline\n",
    "\n",
    "### 4) Track 2.4 — Generate & Repair Predictions\n",
    "\n",
    "### 5) Track 2.5 — Evaluate (Track 2 Metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417c5c08",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cbc8ee",
   "metadata": {},
   "source": [
    "### Track 2.1 — Setup & Loading\n",
    "\n",
    "Main Objective:\n",
    "Prepare the environment by loading libraries, constants, dataset paths, and the existing T5 model checkpoint.\n",
    "\n",
    "2.1A: Import libraries + define slot names\n",
    "\n",
    "2.1B: Load dataset (train/dev/test)\n",
    "\n",
    "2.1C: Load T5 tokenizer + model from your checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca63d02",
   "metadata": {},
   "source": [
    "### 2.1A — Import Libraries & Define Constants\n",
    "\n",
    "Small explanation:\n",
    "This cell loads all the Python libraries we will use and defines the slot names & dataset path. Nothing is executed on the model yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60071026",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ian Chia\\.conda\\envs\\it3386\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded libraries. Ready for next step.\n"
     ]
    }
   ],
   "source": [
    "# 2.1A — Import libraries & define constants\n",
    "\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Slot names (same as Sprint 4)\n",
    "SLOT_NAMES = [\"ACTOR\", \"ACTION\", \"OBJECT\", \"LOCATION\", \"TIME\"]\n",
    "\n",
    "# Dataset path (same as Sprint 4 fixed split)\n",
    "DATA_PATH = Path(\"idea_annotator_sprint4_split_fixed.jsonl\")\n",
    "\n",
    "print(\"Loaded libraries. Ready for next step.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d9a71b",
   "metadata": {},
   "source": [
    "### 2.1B — Load Dataset (train/dev/test)\n",
    "\n",
    "This cell reads your Sprint 4 fixed JSONL file, splits it into train / dev / test, and prepares the test texts + gold JSON slots we’ll need later for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "058b7459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['text', 'target_json', 'split']\n",
      "Train size: 228\n",
      "Dev size:   49\n",
      "Test size:  50\n",
      "\n",
      "Example test text: When a character delivers a speech so powerful that it emotionally moves the others to take action and not lose hope\n",
      "Example gold slots: {'ACTOR': 'character', 'ACTION': 'delivers', 'OBJECT': 'speech', 'LOCATION': '', 'TIME': ''}\n",
      "\n",
      "Dataset loaded and split successfully.\n"
     ]
    }
   ],
   "source": [
    "# 2.1B — Load dataset (train / dev / test) and prepare gold slots for test\n",
    "# (Corrected version: target_json already stored as dict, no need json.loads)\n",
    "\n",
    "df = pd.read_json(DATA_PATH, lines=True)\n",
    "\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "# Split into train / dev / test\n",
    "train_df = df[df[\"split\"] == \"train\"].reset_index(drop=True)\n",
    "dev_df   = df[df[\"split\"] == \"dev\"].reset_index(drop=True)\n",
    "test_df  = df[df[\"split\"] == \"test\"].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train size: {len(train_df)}\")\n",
    "print(f\"Dev size:   {len(dev_df)}\")\n",
    "print(f\"Test size:  {len(test_df)}\")\n",
    "\n",
    "# Expected sizes (safety check)\n",
    "assert len(train_df) == 228\n",
    "assert len(dev_df)   == 49\n",
    "assert len(test_df)  == 50\n",
    "\n",
    "# Prepare test inputs\n",
    "test_texts = test_df[\"text\"].tolist()\n",
    "\n",
    "# Gold slot dicts — already stored as dicts in the file\n",
    "gold_slots_list = test_df[\"target_json\"].tolist()\n",
    "\n",
    "print(\"\\nExample test text:\", test_texts[0])\n",
    "print(\"Example gold slots:\", gold_slots_list[0])\n",
    "print(\"\\nDataset loaded and split successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6347aa2b",
   "metadata": {},
   "source": [
    "### 2.1C — Load T5 Tokenizer & Model from Checkpoint\n",
    "\n",
    "This cell:\n",
    "\n",
    "points to your saved T5 model folder (e.g. ./t5_s4_outputs/)\n",
    "\n",
    "loads the tokenizer and model\n",
    "\n",
    "moves model to GPU if available (else CPU)\n",
    "\n",
    "sets it to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68459383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for T5 checkpoints in: t5_s4_outputs\n",
      " Found T5 checkpoint: t5_s4_outputs\\checkpoint-285\n",
      "Tokenizer loaded from checkpoint folder.\n",
      "\n",
      " T5 model loaded successfully from: t5_s4_outputs\\checkpoint-285\n",
      "Running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "# 2.1C — Load T5 tokenizer & model from latest checkpoint in ./t5_s4_outputs\n",
    "\n",
    "import torch\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_T5_DIR = Path(\"./t5_s4_outputs\")\n",
    "\n",
    "print(\"Looking for T5 checkpoints in:\", BASE_T5_DIR)\n",
    "\n",
    "# 1) Find all checkpoint subfolders, e.g. ./t5_s4_outputs/checkpoint-500\n",
    "checkpoint_dirs = glob.glob(str(BASE_T5_DIR / \"checkpoint-*\"))\n",
    "\n",
    "if not checkpoint_dirs:\n",
    "    raise RuntimeError(\n",
    "        \" No T5 checkpoints found in ./t5_s4_outputs.\\n\"\n",
    "        \"Please open your Sprint4 _track_0_Fixed Split.ipynb notebook,\\n\"\n",
    "        \"run the T5 training cells again (trainer.train()), and then come back here.\"\n",
    "    )\n",
    "\n",
    "# 2) Pick the latest checkpoint based on step number\n",
    "def extract_step(path):\n",
    "    basename = os.path.basename(path)\n",
    "    try:\n",
    "        return int(basename.split(\"-\")[-1])\n",
    "    except ValueError:\n",
    "        return -1\n",
    "\n",
    "checkpoint_dirs = sorted(checkpoint_dirs, key=extract_step)\n",
    "best_ckpt = checkpoint_dirs[-1]\n",
    "\n",
    "print(\" Found T5 checkpoint:\", best_ckpt)\n",
    "\n",
    "# 3) Load tokenizer\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "try:\n",
    "    tokenizer = T5Tokenizer.from_pretrained(best_ckpt)\n",
    "    print(\"Tokenizer loaded from checkpoint folder.\")\n",
    "except Exception as e:\n",
    "    print(\"Could not load tokenizer from checkpoint folder. Reason:\")\n",
    "    print(\" \", e)\n",
    "    print(\"\\nFalling back to base 't5-small' tokenizer (same as used for training).\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "    print(\"Tokenizer loaded from 't5-small'.\")\n",
    "\n",
    "# 4) Load model weights from the same checkpoint\n",
    "model = T5ForConditionalGeneration.from_pretrained(best_ckpt)\n",
    "\n",
    "# 5) Move model to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"\\n T5 model loaded successfully from:\", best_ckpt)\n",
    "print(\"Running on device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ad0670",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c2c5a0",
   "metadata": {},
   "source": [
    "### Track 2.2 — Safer Decoding\n",
    "\n",
    "Main Objective:This makes sures that there will be output and it will\n",
    "make T5 generate cleaner, more predictable JSON by controlling how it produces text. \n",
    "This reduces:\n",
    "\n",
    "- random trailing sentences\n",
    "\n",
    "- half-closed braces\n",
    "\n",
    "- extra noise tokens\n",
    "\n",
    "- unnecessary repetition\n",
    "\n",
    "Track 2.2 does NOT repair JSON yet — it simply makes the raw generation less messy, so the repair step (Track 2.3) becomes easier and more accurate.\n",
    "\n",
    "\n",
    "2.2A: Define safe generation settings\n",
    "\n",
    "2.2B: Test-generation on 1 sentence (sanity check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2a9e74",
   "metadata": {},
   "source": [
    "### 2.2A — Define safe generation settings\n",
    "\n",
    "This cell creates a “safe generation config” you will reuse whenever T5 is generating JSON.\n",
    "These settings reduce junk text, repetition, and incomplete JSON.\n",
    "\n",
    "- disable sampling\n",
    "\n",
    "- encourage T5 to stop early\n",
    "\n",
    "- reduce randomness\n",
    "\n",
    "This makes T5 output more stable JSON-like text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "332a4fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Safe generation settings created.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_length': 128,\n",
       " 'no_repeat_ngram_size': 3,\n",
       " 'repetition_penalty': 1.2,\n",
       " 'early_stopping': True,\n",
       " 'num_beams': 4,\n",
       " 'do_sample': False}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.2A — Define safer generation settings for T5\n",
    "\n",
    "safe_gen_kwargs = {\n",
    "    \"max_length\": 128,\n",
    "    \"no_repeat_ngram_size\": 3,\n",
    "    \"repetition_penalty\": 1.2,\n",
    "    \"early_stopping\": True,\n",
    "    \"num_beams\": 4,            # beam search to reduce randomness\n",
    "    \"do_sample\": False,        # deterministic output\n",
    "}\n",
    "\n",
    "print(\"Safe generation settings created.\")\n",
    "safe_gen_kwargs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd15c6c",
   "metadata": {},
   "source": [
    "### 2.2B — Quick Safe-Decoding Sanity Test\n",
    "\n",
    "This cell will:\n",
    "\n",
    "1) Take one test sentence (the 1st one in your test set)\n",
    "\n",
    "2) Tokenize it\n",
    "\n",
    "3) Run T5 with the safe generation settings\n",
    "\n",
    "4) Print the raw output so we can visually confirm that:\n",
    "    - generation works\n",
    "    - no errors\n",
    "    - T5 produces something JSON-like\n",
    "    - beam search + deterministic decoding is functioning\n",
    "\n",
    "This is NOT repairing JSON yet — just making sure T5 is generating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d11de87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT TEXT:\n",
      "When a character delivers a speech so powerful that it emotionally moves the others to take action and not lose hope\n",
      "\n",
      "--- Generating with safe decoding ---\n",
      "\n",
      "RAW T5 OUTPUT:\n",
      "\"TIME\": \"character\", \"\n"
     ]
    }
   ],
   "source": [
    "# 2.2B — Quick sanity test with safe decoding\n",
    "\n",
    "# Take the first test input\n",
    "sample_text = test_texts[0]\n",
    "\n",
    "print(\"INPUT TEXT:\")\n",
    "print(sample_text)\n",
    "print(\"\\n--- Generating with safe decoding ---\\n\")\n",
    "\n",
    "# Encode the text\n",
    "inputs = tokenizer(\n",
    "    sample_text,\n",
    "    return_tensors=\"pt\",\n",
    "    truncation=True,\n",
    "    padding=True\n",
    ").to(device)\n",
    "\n",
    "# Generate with safe settings\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(\n",
    "        **inputs,\n",
    "        **safe_gen_kwargs\n",
    "    )\n",
    "\n",
    "# Decode to string\n",
    "sample_pred = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"RAW T5 OUTPUT:\")\n",
    "print(sample_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035ccbaa",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50a9d5c",
   "metadata": {},
   "source": [
    "### Track 2.3 — JSON Repair Pipeline\n",
    "\n",
    "Main Objective:\n",
    "Repair invalid JSON produced by T5 so it becomes valid and readable.\n",
    "\n",
    "2.3A: Basic cleanup (remove weird tokens, trim text)\n",
    "\n",
    "2.3B: Structure repair (fix braces/quotes/commas)\n",
    "\n",
    "2.3C: Slot normalization (ensure all 5 slots exist)\n",
    "\n",
    "2.3D: “Full repair” function combining all steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e374ed1b",
   "metadata": {},
   "source": [
    "### 2.3A — Basic Cleanup Helper\n",
    "\n",
    "\n",
    "This cell creates a function that:\n",
    "\n",
    "- trims spaces\n",
    "\n",
    "- removes obvious markdown wrappers (like ```json) if they ever appear\n",
    "\n",
    "- if there’s a { ... } region, it keeps only that inner part (helps when T5 adds extra commentary).\n",
    "\n",
    "This makes the text “cleaner” before we attempt parsing or regex extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d699cb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW: '\"TIME\": \"character\", \"'\n",
      "CLEANED: '\"TIME\": \"character\", \"'\n"
     ]
    }
   ],
   "source": [
    "# 2.3A — Basic cleanup of raw T5 output\n",
    "\n",
    "def clean_raw_text(raw: str) -> str:\n",
    "    \"\"\"\n",
    "    Basic cleanup of the raw T5 string before attempting JSON parsing / regex.\n",
    "    This does NOT guarantee valid JSON, it just removes obvious junk.\n",
    "    \"\"\"\n",
    "    if raw is None:\n",
    "        return \"\"\n",
    "\n",
    "    s = str(raw).strip()\n",
    "\n",
    "    # Remove common markdown wrappers if they appear\n",
    "    for prefix in [\"```json\", \"```\"]:\n",
    "        if s.lower().startswith(prefix):\n",
    "            s = s[len(prefix):].lstrip(\": \\n\")\n",
    "\n",
    "    # If there is a clear JSON block {...}, keep only that region\n",
    "    first_brace = s.find(\"{\")\n",
    "    last_brace = s.rfind(\"}\")\n",
    "    if first_brace != -1 and last_brace != -1 and last_brace > first_brace:\n",
    "        s = s[first_brace:last_brace+1]\n",
    "\n",
    "    return s\n",
    "\n",
    "# Quick test on the sample output you saw\n",
    "test_clean = clean_raw_text(sample_pred)\n",
    "print(\"RAW:\", repr(sample_pred))\n",
    "print(\"CLEANED:\", repr(test_clean))\n",
    "Main Objective:\n",
    "Repair invalid JSON produced by T5 so it becomes valid and readable.\n",
    "\n",
    "2.3A: Basic cleanup (remove weird tokens, trim text)\n",
    "\n",
    "2.3B: Structure repair (fix braces/quotes/commas)\n",
    "\n",
    "2.3C: Slot normalization (ensure all 5 slots exist)\n",
    "\n",
    "2.3D: “Full repair” function combining all steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbfc441",
   "metadata": {},
   "source": [
    "### 2.3B — Attempt JSON Parse (with safe fallback)\n",
    "\n",
    "Small explanation:\n",
    "This function tries:\n",
    "\n",
    "1. Try json.loads(s) normally\n",
    "\n",
    "2. If it fails → we return None\n",
    "    (we will handle this later with regex extraction in 2.3C)\n",
    "\n",
    "This builds the “structured repair” part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "579b1120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed output: None\n"
     ]
    }
   ],
   "source": [
    "# 2.3B — Try to parse cleaned text as JSON\n",
    "\n",
    "def try_json_parse(s: str):\n",
    "    \"\"\"\n",
    "    Attempt to parse the string as JSON.\n",
    "    If it fails, return None (we will fix with regex in 2.3C).\n",
    "    \"\"\"\n",
    "    if not s:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Test on the cleaned sample\n",
    "parsed = try_json_parse(test_clean)\n",
    "print(\"Parsed output:\", parsed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8005634a",
   "metadata": {},
   "source": [
    "### 2.3C — Regex Slot Extraction + Slot Normalization\n",
    "\n",
    "Small explanation:\n",
    "This cell does two things at once:\n",
    "\n",
    "1) Uses regex to find patterns like\n",
    "    \"ACTOR\": \"the hero\"\n",
    "    \"TIME\": \"yesterday\"\n",
    "    even if the overall string is not valid JSON.\n",
    "\n",
    "2) Normalizes them into a dict with exactly these 5 keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5211cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slots extracted via regex from sample:\n",
      "{'ACTOR': '', 'ACTION': '', 'OBJECT': '', 'LOCATION': '', 'TIME': 'character'}\n"
     ]
    }
   ],
   "source": [
    "# 2.3C — Extract slot values using regex + normalize to 5 slots\n",
    "\n",
    "def extract_slots_with_regex(s: str):\n",
    "    \"\"\"\n",
    "    Use a regex to find patterns like \"KEY\": \"value\" and map them\n",
    "    into our 5-slot dict. Any missing slot is filled with \"\".\n",
    "    \"\"\"\n",
    "    # Start with empty slots\n",
    "    slots = {slot: \"\" for slot in SLOT_NAMES}\n",
    "    \n",
    "    if not s:\n",
    "        return slots\n",
    "    \n",
    "    # Regex: optional quotes around key, colon, then quoted value\n",
    "    # Examples it can match:\n",
    "    # \"ACTOR\": \"the hero\"\n",
    "    # ACTOR: \"the hero\"\n",
    "    pattern = r'\"?\\s*([A-Za-z_]+)\\s*\"?\\s*:\\s*\"([^\"]*)\"'\n",
    "    \n",
    "    matches = re.findall(pattern, s)\n",
    "    \n",
    "    for key, value in matches:\n",
    "        key_norm = key.strip().upper()\n",
    "        value_norm = value.strip()\n",
    "        \n",
    "        if key_norm in slots:\n",
    "            slots[key_norm] = value_norm\n",
    "    \n",
    "    return slots\n",
    "\n",
    "# Quick test on the cleaned sample we have\n",
    "regex_slots = extract_slots_with_regex(test_clean)\n",
    "print(\"Slots extracted via regex from sample:\")\n",
    "print(regex_slots)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307175a0",
   "metadata": {},
   "source": [
    "### 2.3D — Full Repair Pipeline (repair_prediction)\n",
    "\n",
    "Small explanation:\n",
    "This step combines everything i have built:\n",
    "\n",
    "- 2.3A: Clean the raw text\n",
    "\n",
    "- 2.3B: Try JSON parsing\n",
    "\n",
    "- 2.3C: Extract slots via regex\n",
    "\n",
    "- Slot normalization: Always produce all 5 slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ee8668b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repaired sample prediction:\n",
      "{'ACTOR': '', 'ACTION': '', 'OBJECT': '', 'LOCATION': '', 'TIME': 'character'}\n"
     ]
    }
   ],
   "source": [
    "# 2.3D — Full repair pipeline combining 2.3A + 2.3B + 2.3C\n",
    "\n",
    "def repair_prediction(raw_text: str):\n",
    "    \"\"\"\n",
    "    Full repair pipeline:\n",
    "    1. Clean raw T5 text\n",
    "    2. Try JSON parsing\n",
    "    3. If JSON parsing fails, extract slots via regex\n",
    "    4. Ensure all 5 slots exist\n",
    "    \"\"\"\n",
    "    # Step 1: basic cleanup\n",
    "    cleaned = clean_raw_text(raw_text)\n",
    "\n",
    "    # Step 2: try real JSON parsing\n",
    "    parsed = try_json_parse(cleaned)\n",
    "    \n",
    "    # If JSON parsing worked and produced a dict\n",
    "    if isinstance(parsed, dict):\n",
    "        # Normalize keys (uppercase) + ensure all 5 slots\n",
    "        final = {slot: \"\" for slot in SLOT_NAMES}\n",
    "        for k, v in parsed.items():\n",
    "            k_norm = str(k).strip().upper()\n",
    "            if k_norm in final:\n",
    "                final[k_norm] = str(v).strip()\n",
    "        return final\n",
    "    \n",
    "    # Step 3: fallback to regex extraction if JSON parse failed\n",
    "    return extract_slots_with_regex(cleaned)\n",
    "\n",
    "# Test on your sample\n",
    "fixed_sample = repair_prediction(sample_pred)\n",
    "print(\"Repaired sample prediction:\")\n",
    "print(fixed_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf470f0",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7459ec99",
   "metadata": {},
   "source": [
    "### Track 2.4 — Generate & Repair Predictions\n",
    "\n",
    "Main Objective:\n",
    "Run T5 on all 50 test sentences → repair each → save into pred_slots_list.\n",
    "\n",
    "- 2.4A: Generate raw predictions (pred_strs)\n",
    "\n",
    "- 2.4B: Apply repair pipeline → pred_slots_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f560fb4",
   "metadata": {},
   "source": [
    "### 2.4A — Generate Raw Predictions (pred_strs)\n",
    "\n",
    "Small explanation:\n",
    "\n",
    "This cell loops through all 50 test sentences and:\n",
    "\n",
    "1) Tokenizes each sentence\n",
    "\n",
    "2) Runs T5 with safe generation settings\n",
    "\n",
    "3) Stores the raw (unrepaired) T5 output in a list called pred_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec48895c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating raw predictions...\n",
      "\n",
      "Example 1:\n",
      "Input: When a character delivers a speech so powerful that it emotionally moves the others to take action and not lose hope\n",
      "Raw T5 Output: \"TIME\": \"character\", \"\n",
      "\n",
      "Example 2:\n",
      "Input: A character who very rarely or never shows any emotion\n",
      "Raw T5 Output: \"ACTOR\": \"character\", \"ACTOR\", \"OBJECT\", \"LOCATION\", \"EXCELLENCE\", \"TIME\": „\"\n",
      "\n",
      "Example 3:\n",
      "Input: Limited color palette on purpose\n",
      "Raw T5 Output: \"Long color palette\": \"limited color palette\", \"Limited color palette on purpose\", \"color palette\" : \"\"\n",
      "\n",
      "Done. Total predictions: 50\n"
     ]
    }
   ],
   "source": [
    "# 2.4A — Generate raw T5 predictions for all 50 test sentences\n",
    "\n",
    "pred_strs = []  # raw T5 outputs\n",
    "\n",
    "print(\"Generating raw predictions...\")\n",
    "for i, text in enumerate(test_texts):\n",
    "    # Encode\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True\n",
    "    ).to(device)\n",
    "\n",
    "    # Generate using safe settings\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            **inputs,\n",
    "            **safe_gen_kwargs\n",
    "        )\n",
    "\n",
    "    # Decode\n",
    "    pred = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    pred_strs.append(pred)\n",
    "\n",
    "    if i < 3:  # print first few\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(\"Input:\", text)\n",
    "        print(\"Raw T5 Output:\", pred)\n",
    "\n",
    "print(\"\\nDone. Total predictions:\", len(pred_strs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b426277",
   "metadata": {},
   "source": [
    "### 2.4B — Apply Repair Pipeline to All Predictions\n",
    "\n",
    "Small explanation:\n",
    "This cell:\n",
    "\n",
    "- Takes each raw T5 output from pred_strs\n",
    "\n",
    "- Runs repair_prediction() on it\n",
    "\n",
    "- Stores the fixed JSON dict in pred_slots_list\n",
    "\n",
    "After this step, you will have:\n",
    "\n",
    "- pred_slots_list → clean, valid predictions ready for evaluation\n",
    "\n",
    "- No invalid JSON\n",
    "\n",
    "- No missing slots\n",
    "\n",
    "- No parser crashes\n",
    "\n",
    "This is the step that removes all the problems that caused Track 0 to fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a45ee3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repairing predictions...\n",
      "\n",
      "Original Raw Prediction 1: \"TIME\": \"character\", \"\n",
      "Repaired: {'ACTOR': '', 'ACTION': '', 'OBJECT': '', 'LOCATION': '', 'TIME': 'character'}\n",
      "\n",
      "Original Raw Prediction 2: \"ACTOR\": \"character\", \"ACTOR\", \"OBJECT\", \"LOCATION\", \"EXCELLENCE\", \"TIME\": „\"\n",
      "Repaired: {'ACTOR': 'character', 'ACTION': '', 'OBJECT': '', 'LOCATION': '', 'TIME': ''}\n",
      "\n",
      "Original Raw Prediction 3: \"Long color palette\": \"limited color palette\", \"Limited color palette on purpose\", \"color palette\" : \"\"\n",
      "Repaired: {'ACTOR': '', 'ACTION': '', 'OBJECT': '', 'LOCATION': '', 'TIME': ''}\n",
      "\n",
      "Done. Total repaired predictions: 50\n"
     ]
    }
   ],
   "source": [
    "# 2.4B — Apply repair pipeline to all raw predictions\n",
    "pred_slots_list = []\n",
    "\n",
    "print(\"Repairing predictions...\")\n",
    "for i, raw in enumerate(pred_strs):\n",
    "    fixed = repair_prediction(raw)\n",
    "    pred_slots_list.append(fixed)\n",
    "\n",
    "    # Show first 3 repaired outputs for inspection\n",
    "    if i < 3:\n",
    "        print(f\"\\nOriginal Raw Prediction {i+1}: {raw}\")\n",
    "        print(\"Repaired:\", fixed)\n",
    "\n",
    "print(\"\\nDone. Total repaired predictions:\", len(pred_slots_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780efb76",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b39a07",
   "metadata": {},
   "source": [
    "### Track 2.5 — Evaluate (Track 2 Metrics)\n",
    "\n",
    "Main Objective:\n",
    "Re-run Slot-F1 and Frame-Validity with fixed JSON so results reflect T5’s true capability.\n",
    "\n",
    "2.5A: Slot-F1 calculation\n",
    "\n",
    "2.5B: Frame-validity %\n",
    "\n",
    "2.5C: Summary of Track 2 improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cb8031",
   "metadata": {},
   "source": [
    "### 2.5A — Compute Slot-Level Precision / Recall / F1\n",
    "\n",
    "Small explanation:\n",
    "This cell compares gold_slots_list vs pred_slots_list and calculates:\n",
    "\n",
    "how many slots are exactly correct (TP)\n",
    "\n",
    "how many are wrong (FP, FN)\n",
    "\n",
    "overall precision, recall, F1\n",
    "\n",
    "The rule we’ll use (simple and sensible):\n",
    "\n",
    "If gold slot is non-empty and prediction matches exactly → TP\n",
    "\n",
    "If prediction is non-empty but wrong → FP + FN\n",
    "\n",
    "If gold slot is non-empty but prediction is empty → FN\n",
    "\n",
    "If both empty → ignored (doesn’t help or hurt)\n",
    "\n",
    "This is a clean, slot-level F1 — good enough and easy to explain in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d35f659b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track 2 — Slot-level metrics\n",
      "TP: 1, FP: 11, FN: 133\n",
      "Precision: 0.0833\n",
      "Recall:    0.0075\n",
      "F1:        0.0137\n"
     ]
    }
   ],
   "source": [
    "# 2.5A — Compute slot-level precision, recall, and F1 across all 5 slots\n",
    "\n",
    "def compute_slot_f1(golds, preds, slot_names=SLOT_NAMES):\n",
    "    tp = 0  # true positives (correct non-empty slot matches)\n",
    "    fp = 0  # predicted something but it was wrong\n",
    "    fn = 0  # gold had something but prediction missed or was wrong\n",
    "\n",
    "    for gold, pred in zip(golds, preds):\n",
    "        for slot in slot_names:\n",
    "            gold_val = str(gold.get(slot, \"\")).strip()\n",
    "            pred_val = str(pred.get(slot, \"\")).strip()\n",
    "\n",
    "            # ignore if both are empty (no information)\n",
    "            if gold_val == \"\" and pred_val == \"\":\n",
    "                continue\n",
    "\n",
    "            if gold_val != \"\" and pred_val == gold_val:\n",
    "                # correct non-empty match\n",
    "                tp += 1\n",
    "            elif gold_val == \"\" and pred_val != \"\":\n",
    "                # predicted something where gold has nothing\n",
    "                fp += 1\n",
    "            elif gold_val != \"\" and pred_val == \"\":\n",
    "                # missed a gold slot\n",
    "                fn += 1\n",
    "            elif gold_val != \"\" and pred_val != \"\" and pred_val != gold_val:\n",
    "                # both non-empty but different → wrong prediction\n",
    "                fp += 1\n",
    "                fn += 1\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall    = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1        = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"tp\": tp,\n",
    "        \"fp\": fp,\n",
    "        \"fn\": fn,\n",
    "    }\n",
    "\n",
    "slot_metrics = compute_slot_f1(gold_slots_list, pred_slots_list)\n",
    "\n",
    "print(\"Track 2 — Slot-level metrics\")\n",
    "print(f\"TP: {slot_metrics['tp']}, FP: {slot_metrics['fp']}, FN: {slot_metrics['fn']}\")\n",
    "print(f\"Precision: {slot_metrics['precision']:.4f}\")\n",
    "print(f\"Recall:    {slot_metrics['recall']:.4f}\")\n",
    "print(f\"F1:        {slot_metrics['f1']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0200f4ce",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "Track 2 successfully repaired T5 outputs into valid JSON, enabling proper evaluation.\n",
    "Although T5’s Slot-F1 remains low (≈0.01), this reveals the model’s true weakness in strictly-structured slot filling.\n",
    "This result justifies moving to BERT token classification in Track 3, which is better suited for structured extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bf889c",
   "metadata": {},
   "source": [
    "### 2.5B — Frame Validity (% of predictions containing all 5 slots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55e90e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track 2 — Frame Validity: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# 2.5B — Compute frame validity (does each prediction contain all 5 slots?)\n",
    "\n",
    "def compute_frame_validity(preds, slot_names=SLOT_NAMES):\n",
    "    valid = 0\n",
    "    total = len(preds)\n",
    "\n",
    "    for frame in preds:\n",
    "        if all(slot in frame for slot in slot_names):\n",
    "            valid += 1\n",
    "\n",
    "    return valid / total if total > 0 else 0.0\n",
    "\n",
    "frame_validity = compute_frame_validity(pred_slots_list)\n",
    "\n",
    "print(f\"Track 2 — Frame Validity: {frame_validity*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a199c3",
   "metadata": {},
   "source": [
    "### Track 2.5C — Final Summary Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c568823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================\n",
      "                 TRACK 2 — FINAL SUMMARY\n",
      "===============================================================\n",
      "\n",
      "Slot-Level Evaluation (ACTOR, ACTION, OBJECT, LOCATION, TIME)\n",
      "  True Positives (TP): 1\n",
      "  False Positives (FP): 11\n",
      "  False Negatives (FN): 133\n",
      "  Precision: 0.0833\n",
      "  Recall:    0.0075\n",
      "  F1 Score:  0.0137\n",
      "\n",
      "Frame Validity (percentage of frames containing all 5 required slots)\n",
      "  Frame Validity: 100.00%\n",
      "\n",
      "Notes:\n",
      "1. Track 0 failed because T5 produced invalid JSON, leading to F1 = 0 and Frame Validity = 0%.\n",
      "2. Track 2 introduced safer decoding and a repair pipeline to fix all invalid outputs.\n",
      "3. As a result, all 50 predictions are now valid JSON structures.\n",
      "4. Track 2 reveals T5's true slot-filling capability: very low F1, but no longer 0.\n",
      "5. This demonstrates that T5-small is not well-suited for strict slot extraction.\n",
      "6. This motivates migrating to BERT-based token classification in Track 3.\n",
      "\n",
      "Track 2 Summary Completed.\n",
      "===============================================================\n"
     ]
    }
   ],
   "source": [
    "# 2.5C — Track 2 Final Summary (T5 Improvements on Sprint 4 Fixed Split)\n",
    "\n",
    "print(\"===============================================================\")\n",
    "print(\"                 TRACK 2 — FINAL SUMMARY\")\n",
    "print(\"===============================================================\\n\")\n",
    "\n",
    "# Slot-level metrics\n",
    "print(\"Slot-Level Evaluation (ACTOR, ACTION, OBJECT, LOCATION, TIME)\")\n",
    "print(f\"  True Positives (TP): {slot_metrics['tp']}\")\n",
    "print(f\"  False Positives (FP): {slot_metrics['fp']}\")\n",
    "print(f\"  False Negatives (FN): {slot_metrics['fn']}\")\n",
    "print(f\"  Precision: {slot_metrics['precision']:.4f}\")\n",
    "print(f\"  Recall:    {slot_metrics['recall']:.4f}\")\n",
    "print(f\"  F1 Score:  {slot_metrics['f1']:.4f}\\n\")\n",
    "\n",
    "# Frame validity\n",
    "print(\"Frame Validity (percentage of frames containing all 5 required slots)\")\n",
    "print(f\"  Frame Validity: {frame_validity * 100:.2f}%\\n\")\n",
    "\n",
    "# Explanation for report clarity\n",
    "print(\"Notes:\")\n",
    "print(\"1. Track 0 failed because T5 produced invalid JSON, leading to F1 = 0 and Frame Validity = 0%.\")\n",
    "print(\"2. Track 2 introduced safer decoding and a repair pipeline to fix all invalid outputs.\")\n",
    "print(\"3. As a result, all 50 predictions are now valid JSON structures.\")\n",
    "print(\"4. Track 2 reveals T5's true slot-filling capability: very low F1, but no longer 0.\")\n",
    "print(\"5. This demonstrates that T5-small is not well-suited for strict slot extraction.\")\n",
    "print(\"6. This motivates migrating to BERT-based token classification in Track 3.\\n\")\n",
    "\n",
    "print(\"Track 2 Summary Completed.\")\n",
    "print(\"===============================================================\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-it3386] *",
   "language": "python",
   "name": "conda-env-.conda-it3386-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
